#!/usr/bin/env python3
"""Test deterministic replay behavior with seeds."""

import asyncio
import hashlib
import json
import logging
import sys
from pathlib import Path
from typing import List, Dict, Any

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from bus import Bus, BusConfig
from ingest import LogReplayer, ReplayConfig, Scenario

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def collect_replay_events(scenario: Scenario, config: ReplayConfig) -> List[Dict[str, Any]]:
    """Collect all events from a replay run."""
    
    # Use in-memory bus (no NATS required)
    bus_config = BusConfig(use_proto=False)
    bus = Bus(bus_config)
    
    events = []
    
    try:
        # Mock bus connection (no actual NATS)
        replayer = LogReplayer(bus, config)
        datasets_dir = Path(__file__).parent.parent / "ingest" / "replay" / "datasets"
        
        async for ecs_event in replayer.replay_scenario(scenario, datasets_dir):
            # Normalize event for comparison (remove timestamps that vary)
            normalized_event = {k: v for k, v in ecs_event.items() if k != "@timestamp"}
            events.append(normalized_event)
        
    except Exception as e:
        logger.error(f"Failed to collect events: {e}")
        raise
    
    return events

def compute_events_hash(events: List[Dict[str, Any]]) -> str:
    """Compute a hash of the events list for comparison."""
    # Sort events by a stable key and compute hash
    events_json = json.dumps(events, sort_keys=True, default=str)
    return hashlib.sha256(events_json.encode()).hexdigest()

async def test_deterministic_replay():
    """Test that replay is deterministic with the same seed."""
    
    test_scenario = Scenario(
        id="deterministic_test",
        name="Deterministic Test",
        description="Test deterministic behavior",
        seed=42,  # Fixed seed
        duration_minutes=1,
        hosts=["test-host-01", "test-host-02"],
        datasets=["zeek_conn_ssh", "osquery_processes_suspicious"]
    )
    
    config = ReplayConfig(
        fast_mode=True,
        add_noise=False,  # Disable noise for deterministic behavior
        host_name="deterministic-test"
    )
    
    logger.info("Running deterministic replay test with seed=42")
    
    # Run replay twice with same seed
    events_run1 = await collect_replay_events(test_scenario, config)
    events_run2 = await collect_replay_events(test_scenario, config)
    
    # Compute hashes
    hash1 = compute_events_hash(events_run1)
    hash2 = compute_events_hash(events_run2)
    
    logger.info(f"Run 1: {len(events_run1)} events, hash: {hash1[:16]}...")
    logger.info(f"Run 2: {len(events_run2)} events, hash: {hash2[:16]}...")
    
    if hash1 == hash2:
        logger.info("âœ… Deterministic test PASSED - same seed produces identical results")
        return True
    else:
        logger.error("âŒ Deterministic test FAILED - same seed produced different results")
        
        # Debug: show first few events from each run
        logger.info("First 3 events from run 1:")
        for i, event in enumerate(events_run1[:3]):
            logger.info(f"  {i}: {event.get('event', {}).get('dataset')} from {event.get('host', {}).get('name')}")
        
        logger.info("First 3 events from run 2:")
        for i, event in enumerate(events_run2[:3]):
            logger.info(f"  {i}: {event.get('event', {}).get('dataset')} from {event.get('host', {}).get('name')}")
        
        return False

async def test_different_seeds():
    """Test that different seeds produce different results."""
    
    base_scenario = Scenario(
        id="seed_test",
        name="Seed Test",
        description="Test different seed behavior",
        duration_minutes=1,
        hosts=["test-host-01"],
        datasets=["zeek_conn_ssh"]
    )
    
    config = ReplayConfig(
        fast_mode=True,
        add_noise=True,  # Enable noise to amplify seed differences
        host_name="seed-test"
    )
    
    logger.info("Testing different seeds produce different results")
    
    # Test with different seeds
    scenario_seed42 = Scenario(**base_scenario.__dict__, seed=42)
    scenario_seed1337 = Scenario(**base_scenario.__dict__, seed=1337)
    
    events_seed42 = await collect_replay_events(scenario_seed42, config)
    events_seed1337 = await collect_replay_events(scenario_seed1337, config)
    
    hash42 = compute_events_hash(events_seed42)
    hash1337 = compute_events_hash(events_seed1337)
    
    logger.info(f"Seed 42: {len(events_seed42)} events, hash: {hash42[:16]}...")
    logger.info(f"Seed 1337: {len(events_seed1337)} events, hash: {hash1337[:16]}...")
    
    if hash42 != hash1337:
        logger.info("âœ… Different seeds test PASSED - different seeds produce different results")
        return True
    else:
        logger.warning("âš ï¸  Different seeds test INCONCLUSIVE - hashes are the same (might be expected for small datasets)")
        return True  # This might be normal for small test datasets

async def test_scenario_loading():
    """Test loading scenarios from YAML file."""
    
    logger.info("Testing scenario loading from YAML")
    
    scenarios_file = Path(__file__).parent.parent / "eval" / "suite" / "scenarios.yml"
    
    try:
        scenarios = LogReplayer.load_scenarios(scenarios_file)
        
        logger.info(f"Loaded {len(scenarios)} scenarios:")
        for scenario in scenarios:
            logger.info(f"  - {scenario.id}: {scenario.name} (seed: {scenario.seed})")
        
        if len(scenarios) > 0:
            logger.info("âœ… Scenario loading test PASSED")
            return True
        else:
            logger.error("âŒ Scenario loading test FAILED - no scenarios loaded")
            return False
            
    except Exception as e:
        logger.error(f"âŒ Scenario loading test FAILED: {e}")
        return False

async def main():
    """Run all deterministic tests."""
    logger.info("Starting CyberSentinel deterministic replay tests")
    
    tests_passed = 0
    total_tests = 0
    
    # Test 1: Deterministic replay
    total_tests += 1
    try:
        if await test_deterministic_replay():
            tests_passed += 1
    except Exception as e:
        logger.error(f"Deterministic replay test error: {e}")
    
    # Test 2: Different seeds
    total_tests += 1
    try:
        if await test_different_seeds():
            tests_passed += 1
    except Exception as e:
        logger.error(f"Different seeds test error: {e}")
    
    # Test 3: Scenario loading
    total_tests += 1
    try:
        if await test_scenario_loading():
            tests_passed += 1
    except Exception as e:
        logger.error(f"Scenario loading test error: {e}")
    
    logger.info("=" * 50)
    logger.info(f"Test Results: {tests_passed}/{total_tests} tests passed")
    
    if tests_passed == total_tests:
        logger.info("ğŸ‰ All deterministic tests passed!")
        return 0
    else:
        logger.error(f"ğŸ’¥ {total_tests - tests_passed} tests failed")
        return 1

if __name__ == "__main__":
    sys.exit(asyncio.run(main()))